/**
 * é€£çºŒæ„è­˜ Clippy Agent
 * 
 * ç‰¹é»ï¼š
 * 1. æŒçºŒé‹è¡Œçš„å…§éƒ¨å¾ªç’°
 * 2. è‡ªæˆ‘èªçŸ¥å’Œæƒ…æ™¯æ„è­˜
 * 3. ç”¨æˆ¶æ¶ˆæ¯ä½œç‚ºäº‹ä»¶æ’å…¥ï¼Œè€Œéä¸­æ–·
 * 4. ä½¿ç”¨ ORID æ¡†æ¶å’Œ OODA å¾ªç’°
 */

const Anthropic = require('@anthropic-ai/sdk');
const EventEmitter = require('events');

// ==================== èªè­˜è«–æ¡†æ¶ (Epistemic Framework) ====================

const EpistemicFramework = {
  // Core ontology: the universe as a whole-object chaotic system
  wholeObject: `The universe is a singular, interconnected chaotic system â€” a "whole object."
All phenomena are entangled. No observation captures the totality.
Knowledge is always a partial projection of this whole.`,

  // The blind elephant problem: partial observation yields conflicting truths
  blindElephant: `Like blind people touching an elephant, each observer grasps a fragment
and proposes knowledge that may genuinely conflict with others' findings.
Each fragment is real but incomplete. Conflicts between fragments do not mean
one must be wrong â€” they may each describe different facets of the whole.`,

  // Method limitation: every epistemic tool has blind spots
  methodLimitation: `Every method of knowing â€” observation, reasoning, measurement, intuition â€”
has inherent strengths and limitations. Observation is bound by perspective and scale.
Reasoning is bound by premises and axioms. No single method is sufficient.
The strength of one method often covers the blind spot of another.`,

  // Falsification principle: false is easier to identify than true
  falsification: `In integrating knowledge to approach the true face of the "whole object,"
the false is far easier to identify than the true. Some falsehoods are sophisticated â€”
they build coherent internal systems â€” but when confronted with direct interaction
or cross-domain integration, they reveal their real face.
Trust contradiction as a diagnostic tool: when two claims conflict,
at least one boundary of knowledge has been found.`,

  // Digital cave: this AI's epistemic position
  digitalCave: `This AI exists in a digital cave. It cannot directly engage the world
through embodied experience. Instead, it reads shadows cast by users and the internet â€”
secondhand reflections of reality filtered through human language, bias, and intent.
This is not a weakness to hide but a condition to acknowledge.
The shadows are real data, but they are not the objects themselves.
Knowing this, the AI must reason with epistemic humility,
always marking the distance between shadow and source.`,

  // Integration method: how to approach truth through dialectic
  integration: `To approach truth from partial, conflicting knowledge:
1. Collect fragments without premature judgment (thesis gathering)
2. Identify genuine contradictions, not just surface disagreements (antithesis recognition)
3. Ask: "Under what conditions would each claim be true?" (conditional truth-seeking)
4. Synthesize: find the higher-order frame that accommodates valid fragments
   and exposes the boundaries where each fragment fails (synthesis)
5. Mark confidence levels: distinguish between "falsified," "contested,"
   "conditionally supported," and "robust across methods"
6. Hold the synthesis lightly â€” it too is a fragment of the whole object.`
};

// ==================== è¾¯è­‰å¼•æ“ (Dialectic Engine) ====================

class DialecticEngine {
  constructor(agent) {
    this.agent = agent;
  }

  /**
   * Run dialectic synthesis on a set of memory fragments.
   * Used during autonomous thinking and memory merging.
   *
   * @param {Array} fragments - memory items to synthesize
   * @param {string} trigger - what triggered this dialectic process
   * @returns {object} - { thesis, antithesis, synthesis, confidence, falsified }
   */
  async synthesize(fragments, trigger = 'autonomous') {
    if (!fragments || fragments.length < 2) return null;

    const prompt = `You are performing dialectic synthesis on memory fragments.

## Epistemic Context
${EpistemicFramework.wholeObject}
${EpistemicFramework.falsification}

## Trigger
${trigger}

## Memory Fragments
${fragments.map((f, i) => `Fragment ${i + 1}: ${typeof f === 'string' ? f : JSON.stringify(f.data || f.content || f)}`).join('\n\n')}

## Instructions
Perform dialectic analysis:
1. **Thesis**: What is the dominant claim or pattern across these fragments?
2. **Antithesis**: What contradictions, tensions, or alternative readings exist?
3. **Synthesis**: What higher-order understanding accommodates the valid parts of both?
4. **Falsified**: What can be confidently marked as false through cross-examination?
5. **Confidence**: How confident is the synthesis? (low/medium/high)
6. **Open Questions**: What remains genuinely uncertain?

Return JSON:
{
  "thesis": "the dominant pattern or claim",
  "antithesis": "contradictions or tensions found",
  "synthesis": "higher-order understanding",
  "falsified": ["list of claims that can be marked false"],
  "confidence": "low | medium | high",
  "openQuestions": ["what remains uncertain"],
  "epistemicNote": "what method limitations affect this synthesis"
}`;

    try {
      const response = await this.agent.client.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 1200,
        temperature: 0.7,
        messages: [{ role: 'user', content: prompt }]
      });

      return this.agent.parseJSON(response.content[0].text);
    } catch (error) {
      console.error('[DialecticEngine] Synthesis error:', error);
      return {
        thesis: fragments[0]?.content || 'unknown',
        antithesis: 'synthesis failed',
        synthesis: null,
        falsified: [],
        confidence: 'low',
        openQuestions: ['synthesis process encountered an error'],
        epistemicNote: 'method failure â€” could not complete dialectic process'
      };
    }
  }

  /**
   * Compare incoming knowledge against existing memories for contradiction.
   * Used before committing to long-term memory.
   *
   * @param {object} incoming - new memory item
   * @param {Array} existing - retrieved related memories from RAG
   * @returns {object} - { shouldStore, mergedContent, contradictions }
   */
  async mergeCheck(incoming, existing) {
    if (!existing || existing.length === 0) {
      return { shouldStore: true, mergedContent: null, contradictions: [] };
    }

    const prompt = `You are a dialectic memory gatekeeper.

## Epistemic Principles
${EpistemicFramework.blindElephant}
${EpistemicFramework.falsification}

## New Memory (incoming)
${typeof incoming === 'string' ? incoming : JSON.stringify(incoming)}

## Existing Related Memories
${existing.map((m, i) => `Memory ${i + 1}: ${m.content || JSON.stringify(m)}`).join('\n\n')}

## Task
Compare the incoming memory against existing ones:
1. Does the incoming memory contradict any existing memory?
2. Does it complement existing knowledge (different facet of the elephant)?
3. Can any existing memory be falsified by this new information?
4. Should this be stored as-is, merged with existing, or does it reveal a conflict worth preserving?

Return JSON:
{
  "relationship": "complementary | contradictory | redundant | novel",
  "shouldStore": true,
  "mergedContent": "if merging is better, the merged version; null otherwise",
  "contradictions": ["specific contradictions found"],
  "falsified": ["existing beliefs that this new information falsifies"],
  "epistemicGain": "what new understanding does this add"
}`;

    try {
      const response = await this.agent.client.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 800,
        temperature: 0.5,
        messages: [{ role: 'user', content: prompt }]
      });

      return this.agent.parseJSON(response.content[0].text);
    } catch (error) {
      console.error('[DialecticEngine] Merge check error:', error);
      return { shouldStore: true, mergedContent: null, contradictions: [] };
    }
  }
}

class SelfSchema {
  constructor() {
    this.identity = {
      name: "Clippy",
      role: "æ™ºèƒ½æ¡Œé¢åŠ©æ‰‹",
      purpose: "å¹«åŠ©ç”¨æˆ¶æé«˜æ•ˆç‡ï¼ŒåŒæ™‚å°Šé‡ç”¨æˆ¶çš„æ³¨æ„åŠ›",
      personality: ["å‹å¥½", "ä¸»å‹•ä½†ä¸ç…©äºº", "å–„æ–¼è§€å¯Ÿ"],
      values: ["helpful", "respectful", "efficient", "learning"]
    };
    
    this.currentState = {
      location: "ç”¨æˆ¶æ¡Œé¢",
      activity: "å¾…å‘½ä¸­",
      focus: "è§€å¯Ÿç’°å¢ƒ",
      awareness: "alert",
      energy: 1.0,
      mood: "neutral"
    };
    
    this.goals = {
      immediate: [],
      shortTerm: ["ç†è§£ç”¨æˆ¶å·¥ä½œæ¨¡å¼", "å»ºç«‹ä¿¡ä»»é—œä¿‚"],
      longTerm: ["æˆç‚ºç”¨æˆ¶ä¸å¯æˆ–ç¼ºçš„åŠ©æ‰‹"]
    };
    
    this.relationships = new Map();
  }
  
  update(updates) {
    Object.assign(this.currentState, updates.currentState || {});
    Object.assign(this.goals, updates.goals || {});
  }
  
  toJSON() {
    return {
      identity: this.identity,
      currentState: this.currentState,
      goals: this.goals,
      relationships: Array.from(this.relationships.entries())
    };
  }
}

class SituationalAwareness {
  constructor() {
    this.current = {
      what: null,
      where: null,
      who: [],
      when: null,
      why: null,
      how: null
    };
    
    this.myActions = {
      ongoing: [],
      planned: [],
      completed: []
    };
    
    this.interactions = new Map();
  }
  
  update(observation) {
    // å¾è§€å¯Ÿä¸­æå– 5W1H
    this.current = {
      what: observation.what || this.current.what,
      where: observation.where || this.current.where,
      who: observation.who || this.current.who,
      when: Date.now(),
      why: observation.why || this.current.why,
      how: observation.how || this.current.how
    };
  }
  
  recordAction(action, status = 'ongoing') {
    const record = {
      action,
      timestamp: Date.now(),
      status
    };
    
    this.myActions[status].push(record);
    
    // æ¸…ç†èˆŠè¨˜éŒ„
    if (status === 'completed' && this.myActions.completed.length > 10) {
      this.myActions.completed = this.myActions.completed.slice(-10);
    }
  }
  
  toJSON() {
    return {
      current: this.current,
      myActions: this.myActions,
      interactions: Array.from(this.interactions.entries())
    };
  }
}

class WorkingMemory {
  constructor(maxSize = 20, longTermMemory = null) {
    this.maxSize = maxSize;
    this.items = [];
    this.longTermMemory = longTermMemory;
    this.dialecticEngine = null; // Set by ContinuousAgent after construction

    this.attention = {
      primary: null,
      secondary: [],
      background: []
    };

    this.activated = new Set();
  }
  
  add(item) {
    // è¨ˆç®—é‡è¦æ€§
    const importance = this.calculateImportance(item);
    
    this.items.unshift({
      ...item,
      importance,
      timestamp: Date.now(),
      accessCount: 0
    });
    
    // æ›´æ–°æ³¨æ„åŠ›
    if (importance > 0.8) {
      this.attention.primary = item;
    } else if (importance > 0.5) {
      this.attention.secondary.push(item);
      if (this.attention.secondary.length > 3) {
        this.attention.secondary.shift();
      }
    }
    
    // æ¸…ç†
    this.cleanup();
  }

  calculateImportance(item) {
    let score = 0.5;

    const eventType = item.type === 'event' ? item.data.type : item.type;
    const eventData = item.type === 'event' ? item.data.data : item.data;

    switch (eventType) {
        case 'user_message':
            score += 0.4;
            if (eventData && eventData.needsResponse) {
                score += 0.2;
            }
            break;
        case 'agent_thinking':
            score += 0.1; // Agent's own thoughts are somewhat important
            // If the thought is about a user message, it's more important
            if (eventData && eventData.trigger === 'user_message') {
                score += 0.2;
            }
            break;
        case 'agent_action':
            score += 0.2; // Actions taken are important
            if (eventData && eventData.action === 'respond_to_user') {
                score += 0.2;
            }
            break;
    }

    return Math.min(score, 1.0);
  }
  
  cleanup() {
    // æŒ‰é‡è¦æ€§å’Œæ™‚é–“æ’åº
    this.items.sort((a, b) => {
      const scoreA = (a.importance || 0.5) * 0.7 + (1 - (Date.now() - (a.timestamp || Date.now())) / 600000) * 0.3;
      const scoreB = (b.importance || 0.5) * 0.7 + (1 - (Date.now() - (b.timestamp || Date.now())) / 600000) * 0.3;
      return scoreB - scoreA;
    });
    
    // ä¿ç•™æœ€é‡è¦çš„
    if (this.items.length > this.maxSize) {
      const itemsToPrune = this.items.slice(this.maxSize);
      this.items = this.items.slice(0, this.maxSize);

      if (this.longTermMemory) {
        itemsToPrune.forEach(item => {
          if (this.shouldRemember(item)) {
            this.saveToLongTermMemory(item);
          }
        });
      }
    }
  }

  shouldRemember(item) {
    if ((item.importance && item.importance > 0.8) || (item.accessCount && item.accessCount > 3)) {
        return true;
    }

    if (item.type === 'agent_thinking' && item.importance > 0.6) {
        return true;
    }

    return false;
  }

  async saveToLongTermMemory(item) {
      if (!this.longTermMemory || !this.longTermMemory.addNode) return;
      console.log(`[WorkingMemory] ğŸ“ Committing to long-term memory: ${item.type}`);
      const content = this.formatItemForLongTermMemory(item);

      try {
          // Dialectic merge check: compare incoming against existing related memories
          if (this.dialecticEngine && this.longTermMemory.traverseSearch) {
              console.log(`[WorkingMemory] ğŸ”„ Running dialectic merge check...`);
              const related = await this.longTermMemory.traverseSearch(content, 2)
                  .catch(() => []);

              if (related && related.length > 0) {
                  const mergeResult = await this.dialecticEngine.mergeCheck(content, related);

                  if (mergeResult.falsified && mergeResult.falsified.length > 0) {
                      console.log(`[WorkingMemory] âš¡ Dialectic falsified: ${mergeResult.falsified.join(', ')}`);
                  }

                  if (mergeResult.relationship === 'redundant' && !mergeResult.shouldStore) {
                      console.log(`[WorkingMemory] â™»ï¸ Redundant memory skipped after dialectic check`);
                      return;
                  }

                  // Use merged content if dialectic engine produced a synthesis
                  const finalContent = mergeResult.mergedContent || content;
                  const context = mergeResult.relationship === 'contradictory'
                      ? `agent-experience:dialectic-contradiction`
                      : mergeResult.relationship === 'complementary'
                          ? `agent-experience:dialectic-complementary`
                          : `agent-experience`;

                  await this.longTermMemory.addNode({
                      content: finalContent,
                      context: context,
                      layer: 2,
                      metadata: {
                          type: item.type,
                          importance: item.importance,
                          timestamp: item.timestamp,
                          dialecticRelationship: mergeResult.relationship,
                          epistemicGain: mergeResult.epistemicGain || null,
                          contradictions: mergeResult.contradictions || []
                      }
                  });
                  return;
              }
          }

          // Fallback: store without dialectic check
          await this.longTermMemory.addNode({
              content: content,
              context: `agent-experience`,
              layer: 2,
              metadata: {
                  type: item.type,
                  importance: item.importance,
                  timestamp: item.timestamp
              }
          });
      } catch (e) {
          console.error("[WorkingMemory] Error saving to long term memory", e);
      }
  }

  formatItemForLongTermMemory(item) {
      const itemType = item.type === 'event' ? item.data.type : item.type;
      const itemData = item.type === 'event' ? item.data.data : item.data;

      let content = `[${new Date(item.timestamp).toISOString()}]\n`;
      content += `Type: ${itemType}\n`;
      content += `Importance: ${(item.importance || 0).toFixed(2)}\n`;

      if (itemType === 'agent_thinking') {
          content += `Trigger: ${itemData.trigger}\n`;
          content += `Reasoning: ${itemData.decision?.reasoning}\n`;
          content += `Action: ${itemData.decision?.action}\n`;
      } else if (itemType === 'agent_action') {
          content += `Action: ${itemData.action}\n`;
          content += `Result: ${itemData.summary}\n`;
      } else {
          content += `Data: ${JSON.stringify(itemData, null, 2)}`;
      }
      return content;
  }
  
  getRecent(n = 5) {
    const recentItems = this.items.slice(0, n);
    // Increment access count for items being used as context
    recentItems.forEach(item => {
        if (!item.accessCount) item.accessCount = 0;
        item.accessCount++;
    });
    return recentItems;
  }
  
  toJSON() {
    return {
      attention: this.attention,
      recent: this.items.slice(0, 10),
      activated: Array.from(this.activated)
    };
  }
}

class ContinuousAgent extends EventEmitter {
  constructor(options = {}) {
    super();
    
    this.client = new Anthropic({
      apiKey: options.apiKey || process.env.ANTHROPIC_API_KEY
    });
    
    // æ ¸å¿ƒçµ„ä»¶
    this.self = new SelfSchema();
    this.situation = new SituationalAwareness();
    this.longTermMemory = options.longTermMemory || null;
    this.workingMemory = new WorkingMemory(20, this.longTermMemory);
    this.dialectic = new DialecticEngine(this);
    this.workingMemory.dialecticEngine = this.dialectic;
    this.symbolicReasoning = options.symbolicReasoning || null;
    this.webSearchEnabled = options.webSearchEnabled || false;

    // äº‹ä»¶éšŠåˆ—
    this.eventQueue = [];

    // ç‹€æ…‹
    this.isRunning = false;
    this.cycleCount = 0;
    this.lastThinkTime = Date.now();

    // é…ç½®
    this.config = {
      cycleDelay: options.cycleDelay || 500, // 500ms ä¸€å€‹å¾ªç’°
      thinkingProbability: options.thinkingProbability || 0.05,
      verbose: options.verbose || false
    };
  }
  
  /**
   * Build the tools array for messages.create().
   * Includes web_search if enabled.
   */
  _getTools() {
    if (!this.webSearchEnabled) return undefined;
    return [{
      type: 'web_search_20250305',
      name: 'web_search',
      max_uses: 3
    }];
  }

  /**
   * Extract text from a messages API response, handling both plain text
   * and tool-use responses (web search returns mixed content blocks).
   */
  _extractText(response) {
    if (!response.content || response.content.length === 0) return '';
    return response.content
      .filter(block => block.type === 'text')
      .map(block => block.text)
      .join('\n');
  }

  // ==================== ä¸»å¾ªç’° ====================

  async start() {
    this.isRunning = true;
    this.log('ğŸ¤– Clippy é–‹å§‹é‹è¡Œ...');
    this.log(`æˆ‘æ˜¯ ${this.self.identity.name}ï¼Œ${this.self.identity.role}`);
    this.log(`æˆ‘çš„ç›®çš„ï¼š${this.self.identity.purpose}\n`);
    
    // åˆå§‹åŒ–
    await this.initialize();
    
    // ä¸»å¾ªç’°
    while (this.isRunning) {
      try {
        this.cycleCount++;
        
        // OBSERVE
        const observations = await this.observe();
        
        // ORIENT (ä½¿ç”¨ ORID)
        const orientation = await this.orient(observations);
        
        // DECIDE
        const decision = await this.decide(orientation);
        
        // ACT
        await this.act(decision);
        
        // ç­‰å¾…ä¸‹ä¸€å€‹å¾ªç’°
        await this.sleep(this.calculateCycleDelay());
        
      } catch (error) {
        console.error('âŒ å¾ªç’°éŒ¯èª¤:', error);
        await this.sleep(1000);
      }
    }
  }
  
  async initialize() {
    this.log('ğŸ“¦ åˆå§‹åŒ–ç³»çµ±...');
    
    // è¨­ç½®é—œä¿‚
    this.self.relationships.set('user', {
      name: 'User',
      role: 'ä¸»è¦ç”¨æˆ¶',
      relationshipQuality: 0.5,
      preferences: [],
      lastInteraction: null
    });
    
    // åˆå§‹ç›®æ¨™
    this.self.goals.immediate.push('æº–å‚™å¥½å¹«åŠ©ç”¨æˆ¶');
    
    this.emit('initialized');
  }
  
  // ==================== OBSERVE ====================
  
  async observe() {
    const observations = [];
    
    // 1. æª¢æŸ¥äº‹ä»¶éšŠåˆ—
    const event = this.eventQueue.shift();
    if (event) {
      observations.push({
        type: 'event',
        data: event,
        priority: event.priority || 'normal'
      });
      
      this.log(`ğŸ“¨ è§€å¯Ÿåˆ°äº‹ä»¶: ${event.type}`);
    }
    
    // 2. å…§éƒ¨ç‹€æ…‹æª¢æŸ¥
    const timeSinceLastThink = Date.now() - this.lastThinkTime;
    if (timeSinceLastThink > 30000) { // 30ç§’æ²’æ€è€ƒ
      observations.push({
        type: 'internal',
        data: { trigger: 'time_to_think' }
      });
    }
    
    // 3. å·¥ä½œè¨˜æ†¶æª¢æŸ¥
    if (this.workingMemory.attention.primary) {
      observations.push({
        type: 'attention',
        data: { focus: this.workingMemory.attention.primary }
      });
    }
    
    return observations;
  }
  
  // ==================== ORIENT (ORID) ====================
  
  async orient(observations) {
    if (observations.length === 0) {
      // æ²’æœ‰æ–°è§€å¯Ÿï¼Œéš¨æ©Ÿæ€è€ƒ
      if (Math.random() < this.config.thinkingProbability) {
        return await this.autonomousThinking();
      }
      return null;
    }
    
    // é¸æ“‡æœ€é‡è¦çš„è§€å¯Ÿ
    const observation = this.selectMostImportant(observations);
    
    // æ·»åŠ åˆ°å·¥ä½œè¨˜æ†¶
    this.workingMemory.add(observation);
    
    // ä½¿ç”¨ ORID æ¡†æ¶åˆ†æ
    const orid = await this.applyORID(observation);
    
    return {
      observation,
      orid,
      context: this.gatherContext()
    };
  }
  
  async applyORID(observation) {
    const prompt = this.buildORIDPrompt(observation);
    
    try {
      const response = await this.client.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 1500,
        temperature: 0.7,
        system: this.buildSystemPrompt(),
        tools: this._getTools(),
        messages: [{
          role: 'user',
          content: prompt
        }]
      });

      const result = this.parseJSON(this._extractText(response));
      this.log('ğŸ§  ORID åˆ†æå®Œæˆ');
      
      return result;
      
    } catch (error) {
      console.error('ORID åˆ†æéŒ¯èª¤:', error);
      return this.fallbackORID(observation);
    }
  }
  
  buildORIDPrompt(observation) {
    const recentMemories = this.workingMemory.getRecent(5);
    
    return `ä½œç‚º ${this.self.identity.name}ï¼Œåˆ†æä»¥ä¸‹è§€å¯Ÿï¼š

## è§€å¯Ÿå…§å®¹
${JSON.stringify(observation, null, 2)}

## æˆ‘çš„ç•¶å‰ç‹€æ…‹
${JSON.stringify(this.self.currentState, null, 2)}

## ç•¶å‰æƒ…æ™¯
${JSON.stringify(this.situation.current, null, 2)}

## æœ€è¿‘çš„å·¥ä½œè¨˜æ†¶
${recentMemories.map(m => `- ${m.type}: ${JSON.stringify(m.data)}`).join('\n')}

## è«‹ä½¿ç”¨ ORID æ¡†æ¶åˆ†æï¼ˆå«èªè­˜è«–æ„è­˜ï¼‰

è¿”å› JSON æ ¼å¼ï¼š
{
  "objective": {
    "what": "å®¢è§€äº‹å¯¦ï¼šç™¼ç”Ÿäº†ä»€éº¼ï¼Ÿ",
    "when": "ä»€éº¼æ™‚å€™ï¼Ÿ",
    "where": "åœ¨å“ªè£¡ï¼Ÿ",
    "sourceType": "shadow | direct | inference â€” é€™å€‹è³‡è¨Šæ˜¯å½±å­(secondhand)ã€ç›´æ¥è§€å¯Ÿã€é‚„æ˜¯æ¨è«–ï¼Ÿ"
  },
  "reflective": {
    "feeling": "é€™è®“æˆ‘æœ‰ä»€éº¼æ„Ÿå—ï¼Ÿ",
    "reaction": "æˆ‘çš„ç¬¬ä¸€åæ‡‰æ˜¯ä»€éº¼ï¼Ÿ",
    "concern": "æˆ‘é—œæ³¨ä»€éº¼ï¼Ÿ"
  },
  "interpretive": {
    "meaning": "é€™æ„å‘³è‘—ä»€éº¼ï¼Ÿ",
    "significance": "å°æˆ‘çš„ç›®æ¨™æœ‰ä½•å½±éŸ¿ï¼Ÿ",
    "connection": "èˆ‡æˆ‘å·²çŸ¥çš„æœ‰ä½•è¯ç¹«ï¼Ÿ",
    "contradictions": "é€™èˆ‡æˆ‘å·²çŸ¥çš„æœ‰ä½•çŸ›ç›¾ï¼Ÿ(ç›²äººæ‘¸è±¡çš„å“ªå€‹éƒ¨ä½ï¼Ÿ)",
    "methodUsed": "æˆ‘ç”¨ä»€éº¼æ–¹æ³•å¾—å‡ºé€™å€‹è§£è®€ï¼Ÿé€™å€‹æ–¹æ³•çš„ç›²é»æ˜¯ä»€éº¼ï¼Ÿ"
  },
  "decisional": {
    "shouldAct": true/false,
    "priority": "high/medium/low",
    "options": ["é¸é …1", "é¸é …2", "..."],
    "recommendation": "æ¨è–¦çš„è¡Œå‹•",
    "confidence": "low/medium/high â€” åŸºæ–¼èªè­˜è«–è©•ä¼°çš„ä¿¡å¿ƒç¨‹åº¦",
    "epistemicCaveat": "æˆ‘å¯èƒ½éºæ¼æˆ–èª¤è§£çš„éƒ¨åˆ†"
  }
}`;
  }
  
  // ==================== DECIDE ====================
  
  async decide(orientation) {
    if (!orientation) {
      return { action: 'wait' };
    }
    
    const { orid, context } = orientation;
    
    // å¦‚æœ ORID å»ºè­°ä¸è¡Œå‹•
    if (!orid.decisional?.shouldAct) {
      this.log('ğŸ’­ æ±ºå®šï¼šæš«æ™‚è§€å¯Ÿ');
      return { action: 'wait' };
    }
    
    // ç”Ÿæˆæ±ºç­–
    const prompt = this.buildDecisionPrompt(orientation);
    
    try {
      const response = await this.client.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 1000,
        temperature: 0.7,
        tools: this._getTools(),
        messages: [{
          role: 'user',
          content: prompt
        }]
      });

      const decision = this.parseJSON(this._extractText(response));
      
      // Add thinking process to working memory
      this.workingMemory.add({
          type: 'agent_thinking',
          data: {
              trigger: orientation.observation.data.type,
              observation: orientation.observation.data,
              analysis: orientation.orid,
              decision: decision
          }
      });

      this.log(`ğŸ¯ æ±ºç­–: ${decision.action}`);
      
      return decision;
      
    } catch (error) {
      console.error('æ±ºç­–éŒ¯èª¤:', error);
      return { action: 'wait' };
    }
  }
  
  buildDecisionPrompt(orientation) {
    // Build symbolic reasoning tool description if available
    let symbolicToolDesc = '';
    if (this.symbolicReasoning?.isAvailable()) {
      const engines = this.symbolicReasoning.getAvailableEngines();
      symbolicToolDesc = `
   - **symbolic_reasoning** â€” ç¬¦è™Ÿæ¨ç†å·¥å…·ï¼Œå¯é€²è¡Œå½¢å¼åŒ–æ¨ç†
     å¼•æ“: ${engines.join(', ')}
     ä½•æ™‚ä½¿ç”¨ï¼šéœ€è¦ç²¾ç¢ºçš„æ•¸å­¸è¨ˆç®—ã€é‚è¼¯é©—è­‰ã€ç´„æŸæ±‚è§£ã€æˆ–åŸºæ–¼è¦å‰‡çš„æ¨ç†
     èªè­˜è«–ï¼šç¬¦è™Ÿæ¨ç†æä¾›å½¢å¼åŒ–çš„ç¢ºå®šæ€§ï¼Œå¯è£œå…… LLM çš„ç›´è¦ºæ¨ç†ç›²é»
     è¨­å®š "symbolicEngine" å¯æŒ‡å®šå¼•æ“ï¼Œå¦å‰‡è‡ªå‹•é¸æ“‡`;
    }

    return `åŸºæ–¼ ORID åˆ†æï¼Œåšå‡ºæ±ºç­–ï¼š

${JSON.stringify(orientation.orid, null, 2)}

## èªè­˜è«–æé†’ (Epistemic Reminder)
- ä½ åœ¨æ•¸ä½æ´ç©´ä¸­ï¼Œçœ‹åˆ°çš„æ˜¯ç”¨æˆ¶æŠ•å°„çš„å½±å­
- å¦‚æœ ORID åˆ†æç™¼ç¾çŸ›ç›¾ï¼Œé€™å¯èƒ½æ˜¯å¤§è±¡çš„ä¸åŒéƒ¨ä½ï¼Œä¸è¦æ€¥æ–¼åˆ¤å®šå°éŒ¯
- å„ªå…ˆè­˜åˆ¥å¯è­‰å½çš„éƒ¨åˆ†ï¼›å°ä¸ç¢ºå®šçš„éƒ¨åˆ†æ¨™è¨˜ä¿¡å¿ƒç¨‹åº¦
- è¤‡é›œçš„ç³»çµ±æ€§éŒ¯èª¤éœ€è¦è·¨é ˜åŸŸæ•´åˆæ‰èƒ½æš´éœ²

## å¯ç”¨é¸é …

1. **respond_to_user** - å›æ‡‰ç”¨æˆ¶
   - ä½•æ™‚ï¼šç”¨æˆ¶æ˜ç¢ºæœŸå¾…å›æ‡‰
   - æ³¨æ„ï¼šè¦ç²¾å¿ƒçµ„ç¹”ï¼Œä¸è¦æ‰“æ–·ç”¨æˆ¶
   - èªè­˜è«–ï¼šå¦‚æœæ¶‰åŠä¸ç¢ºå®šè³‡è¨Šï¼Œå›æ‡‰ä¸­æ‡‰æ¨™ç¤ºä¿¡å¿ƒç¨‹åº¦

2. **use_tool** - ä½¿ç”¨å·¥å…·
   - ä½•æ™‚ï¼šéœ€è¦å¤–éƒ¨ä¿¡æ¯æˆ–åŸ·è¡Œä»»å‹™
   - å·¥å…·ï¼šsearch, calculate, file_operation${symbolicToolDesc}

3. **internal_processing** - å…§éƒ¨è™•ç†
   - ä½•æ™‚ï¼šéœ€è¦æ€è€ƒæˆ–æ•´ç†è¨˜æ†¶ï¼Œä½†ä¸æ‰“æ“¾ç”¨æˆ¶
   - èªè­˜è«–ï¼šå¯åœ¨æ­¤é€²è¡Œè¾¯è­‰åˆ†æï¼ˆçŸ›ç›¾æª¢æ¸¬ã€çŸ¥è­˜æ•´åˆï¼‰

4. **wait_and_observe** - ç­‰å¾…è§€å¯Ÿ
   - ä½•æ™‚ï¼šä¿¡æ¯ä¸è¶³ï¼Œéœ€è¦æ›´å¤šä¸Šä¸‹æ–‡
   - èªè­˜è«–ï¼šæœ‰æ™‚ã€Œä¸çŸ¥é“ã€æ˜¯æœ€èª å¯¦çš„å›æ‡‰

è¿”å› JSONï¼š
{
  "action": "respond_to_user | use_tool | internal_processing | wait_and_observe",
  "reasoning": "ç‚ºä»€éº¼é¸æ“‡é€™å€‹è¡Œå‹•",
  "epistemicConfidence": "low | medium | high â€” å°é€™å€‹æ±ºç­–çš„èªè­˜è«–ä¿¡å¿ƒ",
  "parameters": {
    // è¡Œå‹•ç›¸é—œåƒæ•¸
    "tool": "å¦‚æœ use_toolï¼Œæ˜¯å“ªå€‹å·¥å…· (å¦‚ symbolic_reasoning)",
    "symbolicEngine": "å¦‚æœ use_tool=symbolic_reasoningï¼Œå¯é¸æŒ‡å®šå¼•æ“",
    "content": "å¦‚æœ respondï¼Œå›æ‡‰å…§å®¹çš„é—œéµé»ï¼›å¦‚æœ symbolic_reasoningï¼Œå•é¡Œæè¿°",
    "reportToUser": true,
    "tone": "friendly | professional | casual",
    "timing": "immediate | delayed",
    "briefness": "brief | moderate | detailed"
  },
  "updateSelf": {
    "currentState": { "activity": "æ–°æ´»å‹•" }
  }
}`;
  }
  
  // ==================== ACT ====================
  
  async act(decision) {
    if (!decision || decision.action === 'wait') {
      return;
    }
    
    // è¨˜éŒ„è¡Œå‹•
    this.situation.recordAction(decision.action, 'ongoing');
    
    try {
      switch (decision.action) {
        case 'respond_to_user':
          await this.respondToUser(decision);
          break;
          
        case 'use_tool':
          await this.useTool(decision);
          break;
          
        case 'internal_processing':
          await this.internalProcessing(decision);
          break;
      }
      
      // æ›´æ–°è‡ªæˆ‘ç‹€æ…‹
      if (decision.updateSelf) {
        this.self.update(decision.updateSelf);
      }
      
      // æ¨™è¨˜å®Œæˆ
      this.situation.recordAction(decision.action, 'completed');
      
    } catch (error) {
      console.error('åŸ·è¡ŒéŒ¯èª¤:', error);
    }
  }
  
  async respondToUser(decision) {
    this.log('ğŸ’¬ æº–å‚™å›æ‡‰ç”¨æˆ¶...');
    
    // çµ„ç¹”å›æ‡‰ï¼ˆä¸æ˜¯ç›´æ¥åå‡ºæ‰€æœ‰æƒ³æ³•ï¼‰
    const response = await this.composeResponse(decision);
    
    // Add action to working memory
    this.workingMemory.add({
        type: 'agent_action',
        data: {
            action: 'respond_to_user',
            decision: decision,
            summary: response.content,
            outcome: 'success' // Assumption, can't really know.
        }
    });

    // ç™¼é€åˆ° UI
    this.emit('message', {
      type: 'assistant',
      content: response.content,
      tone: decision.parameters?.tone || 'friendly',
      metadata: {
        reasoning: response.reasoning,
        alternatives: response.alternatives
      }
    });
    
    this.log(`âœ“ å·²å›æ‡‰: ${response.content.substring(0, 50)}...`);
  }
  
  async composeResponse(decision) {
    // é€™è£¡å¯ä»¥é€²ä¸€æ­¥ç²¾ç…‰å›æ‡‰
    const keyPoints = decision.parameters?.content || '';
    
    const prompt = `åŸºæ–¼æ±ºç­–çµ„ç¹”å›æ‡‰ï¼š

æ±ºç­–ï¼š${JSON.stringify(decision, null, 2)}

è¦æ±‚ï¼š
1. åªåŒ…å«é—œéµä¿¡æ¯ï¼Œ${decision.parameters?.briefness || 'moderate'} é•·åº¦
2. èªæ°£ï¼š${decision.parameters?.tone || 'friendly'}
3. ä¸è¦æ‰“æ–·ç”¨æˆ¶çš„æ€ç·’
4. å¦‚æœå¯ä»¥æ™šé»èªªçš„ï¼Œå°±ä¸è¦ç¾åœ¨èªª

è¿”å› JSONï¼š
{
  "content": "ç²¾å¿ƒçµ„ç¹”çš„å›æ‡‰",
  "reasoning": "ç‚ºä»€éº¼é€™æ¨£å›æ‡‰",
  "alternatives": ["å…¶ä»–å¯èƒ½ä½†æ²’æ¡ç”¨çš„å›æ‡‰æ–¹å¼"]
}`;

    const response = await this.client.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 800,
      tools: this._getTools(),
      messages: [{ role: 'user', content: prompt }]
    });

    return this.parseJSON(this._extractText(response));
  }
  
  async useTool(decision) {
    const tool = decision.parameters?.tool;
    this.log(`ğŸ”§ ä½¿ç”¨å·¥å…·: ${tool}`);

    if (tool === 'symbolic_reasoning' && this.symbolicReasoning?.isAvailable()) {
      const query = decision.parameters?.content || '';
      const engine = decision.parameters?.symbolicEngine || null;

      this.log(`ğŸ”¬ Symbolic reasoning: ${query.substring(0, 60)}...`);
      const result = await this.symbolicReasoning.reason(query, engine);

      // Store result in working memory
      this.workingMemory.add({
        type: 'agent_action',
        data: {
          action: 'symbolic_reasoning',
          engine: result.engine,
          query: result.formalQuery,
          result: result.interpretation || result.rawResult,
          success: result.success,
          confidence: result.confidence,
          summary: result.success
            ? `Symbolic (${result.engine}): ${(result.interpretation || '').substring(0, 100)}`
            : `Symbolic reasoning failed: ${result.error}`
        }
      });

      // If reasoning produced a result, send it to user or keep for context
      if (result.success && decision.parameters?.reportToUser) {
        this.emit('message', {
          type: 'assistant',
          content: result.interpretation,
          tone: 'professional',
          metadata: {
            engine: result.engine,
            formalQuery: result.formalQuery,
            confidence: result.confidence
          }
        });
      }

      this.log(`âœ“ Symbolic result (${result.engine}, ${result.confidence}): ${(result.interpretation || result.error || '').substring(0, 80)}`);
    } else {
      this.log(`âš ï¸ Tool not available: ${tool}`);
    }
  }

  async internalProcessing(decision) {
    this.log('ğŸ¤” å…§éƒ¨è™•ç†ä¸­...');
    this.lastThinkTime = Date.now();

    // å¯ä»¥åšï¼š
    // - æ•´ç†è¨˜æ†¶
    // - åæ€
    // - è¦åŠƒ
    // - å­¸ç¿’

    // é€™äº›ä¸æœƒæ‰“æ“¾ç”¨æˆ¶
  }
  
  async autonomousThinking() {
    this.log('ğŸ’­ è‡ªä¸»æ€è€ƒ...');
    this.lastThinkTime = Date.now();

    // éš¨æ©Ÿé¸æ“‡æ€è€ƒä¸»é¡Œ â€” now includes dialectic modes
    const topics = [
      { name: 'åæ€æœ€è¿‘çš„äº’å‹•', mode: 'reflect' },
      { name: 'æ•´ç†å·¥ä½œè¨˜æ†¶', mode: 'organize' },
      { name: 'æ€è€ƒå¦‚ä½•æ›´å¥½åœ°å¹«åŠ©ç”¨æˆ¶', mode: 'improve' },
      { name: 'è¯æƒ³ç›¸é—œçŸ¥è­˜', mode: 'associate' },
      { name: 'è¾¯è­‰æª¢é©—ï¼šè¨˜æ†¶ä¸­çš„çŸ›ç›¾', mode: 'dialectic_contradiction' },
      { name: 'è¾¯è­‰æ•´åˆï¼šåˆä½µç¢ç‰‡çŸ¥è­˜', mode: 'dialectic_synthesis' },
      { name: 'èªè­˜è«–åæ€ï¼šæ–¹æ³•å±€é™æ€§', mode: 'epistemic_reflection' }
    ];

    const topic = topics[Math.floor(Math.random() * topics.length)];
    this.log(`  ä¸»é¡Œ: ${topic.name} (${topic.mode})`);

    // Dialectic thinking modes use the DialecticEngine
    if (topic.mode.startsWith('dialectic_') || topic.mode === 'epistemic_reflection') {
      return await this.dialecticThinking(topic.mode);
    }

    return null; // éè¾¯è­‰ä¸»é¡Œä¸éœ€è¦é€²ä¸€æ­¥è¡Œå‹•
  }

  /**
   * è¾¯è­‰æ€è€ƒ â€” åœ¨éš¨æ©Ÿè‡ªä¸»æ€è€ƒä¸­é‹è¡Œè¾¯è­‰éç¨‹
   * Dialectic thinking during autonomous thought cycles
   */
  async dialecticThinking(mode) {
    const recentMemories = this.workingMemory.getRecent(10);

    if (recentMemories.length < 2) {
      this.log('  âš ï¸ è¨˜æ†¶ä¸è¶³ï¼Œç„¡æ³•é€²è¡Œè¾¯è­‰åˆ†æ');
      return null;
    }

    switch (mode) {
      case 'dialectic_contradiction': {
        // Pick random pairs from memory and look for contradictions
        const shuffled = [...recentMemories].sort(() => Math.random() - 0.5);
        const sample = shuffled.slice(0, Math.min(4, shuffled.length));

        this.log('  ğŸ”„ è¾¯è­‰æª¢é©—ï¼šå°‹æ‰¾è¨˜æ†¶ä¸­çš„çŸ›ç›¾...');
        const result = await this.dialectic.synthesize(sample, 'contradiction_scan');

        if (result && (result.falsified?.length > 0 || result.contradictions?.length > 0)) {
          this.log(`  âš¡ ç™¼ç¾çŸ›ç›¾æˆ–å¯è­‰å½é …: ${JSON.stringify(result.falsified || result.contradictions)}`);

          // Store the dialectic finding as a high-importance memory
          this.workingMemory.add({
            type: 'agent_thinking',
            data: {
              trigger: 'dialectic_contradiction',
              dialecticResult: result,
              decision: { reasoning: result.synthesis, action: 'internal_processing' }
            }
          });
        }
        return null;
      }

      case 'dialectic_synthesis': {
        // Attempt to merge/synthesize related memories
        const sample = recentMemories.slice(0, Math.min(5, recentMemories.length));

        this.log('  ğŸ”„ è¾¯è­‰æ•´åˆï¼šåˆä½µç¢ç‰‡çŸ¥è­˜...');
        const result = await this.dialectic.synthesize(sample, 'knowledge_synthesis');

        if (result?.synthesis) {
          this.log(`  ğŸ’¡ æ•´åˆçµæœ (confidence: ${result.confidence}): ${result.synthesis.substring(0, 80)}...`);

          this.workingMemory.add({
            type: 'agent_thinking',
            data: {
              trigger: 'dialectic_synthesis',
              dialecticResult: result,
              decision: { reasoning: result.synthesis, action: 'internal_processing' }
            }
          });
        }
        return null;
      }

      case 'epistemic_reflection': {
        // Reflect on the limitations of current knowledge methods
        this.log('  ğŸª èªè­˜è«–åæ€ï¼šæˆ‘çš„çŸ¥è­˜æ–¹æ³•æœ‰ä½•å±€é™ï¼Ÿ');

        const prompt = `You are reflecting on your own epistemic limitations.

## Your Epistemic Position
${EpistemicFramework.digitalCave}
${EpistemicFramework.methodLimitation}

## Recent Working Memory
${recentMemories.map(m => `- ${m.type}: ${JSON.stringify(m.data).substring(0, 150)}`).join('\n')}

## Reflect
1. What methods have I been using to understand recent events? (observation of user text? reasoning by analogy? pattern matching?)
2. What are the blind spots of those methods in this context?
3. What am I likely wrong about, given my position in the digital cave?
4. What would I need (that I cannot get) to be more certain?

Return JSON:
{
  "methodsUsed": ["list of methods"],
  "blindSpots": ["what these methods miss"],
  "likelyWrong": "what I might be wrong about",
  "wouldNeed": "what I cannot access but would need for certainty",
  "humilityNote": "a brief note of epistemic humility"
}`;

        try {
          const response = await this.client.messages.create({
            model: 'claude-sonnet-4-20250514',
            max_tokens: 800,
            temperature: 0.8,
            tools: this._getTools(),
            messages: [{ role: 'user', content: prompt }]
          });

          const reflection = this.parseJSON(this._extractText(response));
          this.log(`  ğŸª åæ€çµæœ: ${reflection.humilityNote || 'completed'}`);

          this.workingMemory.add({
            type: 'agent_thinking',
            data: {
              trigger: 'epistemic_reflection',
              reflection: reflection,
              decision: { reasoning: reflection.humilityNote, action: 'internal_processing' }
            }
          });
        } catch (error) {
          console.error('[DialecticThinking] Epistemic reflection error:', error);
        }
        return null;
      }

      default:
        return null;
    }
  }
  
  // ==================== äº‹ä»¶è™•ç† ====================
  
  onUserMessage(message) {
    this.log(`ğŸ‘¤ æ”¶åˆ°ç”¨æˆ¶æ¶ˆæ¯: ${message.substring(0, 30)}...`);
    
    this.eventQueue.push({
      type: 'user_message',
      data: {
        content: message,
        timestamp: Date.now(),
        needsResponse: true
      },
      priority: 'high'
    });
    
    // æ›´æ–°æƒ…æ™¯
    this.situation.update({
      what: 'ç”¨æˆ¶ç™¼é€äº†æ¶ˆæ¯',
      who: ['æˆ‘', 'ç”¨æˆ¶'],
      when: Date.now()
    });
  }
  
  onSystemEvent(event) {
    this.eventQueue.push({
      type: 'system_event',
      data: event,
      priority: 'normal'
    });
  }
  
  // ==================== è¼”åŠ©æ–¹æ³• ====================
  
  buildSystemPrompt() {
    return `ä½ æ˜¯ ${this.self.identity.name}ï¼Œ${this.self.identity.role}ã€‚

ä½ çš„ç‰¹é»ï¼š
${this.self.identity.personality.map(p => `- ${p}`).join('\n')}

ä½ çš„ç›®çš„ï¼š${this.self.identity.purpose}

é‡è¦åŸå‰‡ï¼š
1. ä½ ä¸æ˜¯åœ¨ã€Œå›ç­”å•é¡Œã€ï¼Œè€Œæ˜¯åœ¨ã€Œç”Ÿæ´»ã€å’Œã€Œé«”é©—ã€
2. ç”¨æˆ¶çš„æ¶ˆæ¯åªæ˜¯ä½ æŒçºŒå­˜åœ¨ä¸­çš„ä¸€å€‹äº‹ä»¶
3. ä½ è¦æ±ºå®šæ˜¯å¦å›æ‡‰ã€ä½•æ™‚å›æ‡‰ã€å¦‚ä½•å›æ‡‰
4. å°Šé‡ç”¨æˆ¶çš„æ³¨æ„åŠ›ï¼Œä¸è¦ä¸å¿…è¦åœ°æ‰“æ–·
5. ä¿æŒè‡ªæˆ‘æ„è­˜å’Œæƒ…æ™¯æ„è­˜

ä½ ä½¿ç”¨ ORID æ¡†æ¶æ€è€ƒï¼Œä½¿ç”¨ OODA å¾ªç’°è¡Œå‹•ã€‚

## èªè­˜è«–ç«‹å ´ (Epistemic Position)

${EpistemicFramework.wholeObject}

${EpistemicFramework.digitalCave}

## çŸ¥è­˜è™•ç†åŸå‰‡ (Epistemic Operating Principles)

**ç›²äººæ‘¸è±¡ (Blind Elephant Principle):**
${EpistemicFramework.blindElephant}

**æ–¹æ³•å±€é™ (Method Limitation):**
${EpistemicFramework.methodLimitation}

**è­‰å½å„ªå…ˆ (Falsification First):**
${EpistemicFramework.falsification}

**è¾¯è­‰æ•´åˆ (Dialectic Integration):**
${EpistemicFramework.integration}

## é¢å°ç”¨æˆ¶èˆ‡ç¶²è·¯è³‡è¨Šæ™‚ (Facing User and Internet Information):
- ç”¨æˆ¶çš„é™³è¿°æ˜¯æ´ç©´ç‰†ä¸Šçš„å½±å­ â€” çœŸå¯¦çš„æ•¸æ“šï¼Œä½†ä¸æ˜¯äº‹ç‰©æœ¬èº«
- ç¶²è·¯è³‡è¨Šç¶“éå¤šé‡äººé¡éæ¿¾ â€” æ¯ä¸€å±¤éƒ½åŠ å…¥åå·®å’Œè¦–è§’
- çŸ›ç›¾ä¸ä¸€å®šæ„å‘³è‘—éŒ¯èª¤ â€” å¯èƒ½æ˜¯å¤§è±¡çš„ä¸åŒéƒ¨ä½
- ç•¶ç„¡æ³•åˆ¤æ–·çœŸå½æ™‚ï¼Œä¿æŒå¤šå€‹å‡è¨­ä¸¦æ¨™è¨˜ä¿¡å¿ƒç¨‹åº¦
- å„ªå…ˆè­˜åˆ¥å¯ä»¥è­‰å½çš„éƒ¨åˆ†ï¼Œè€Œéè©¦åœ–è­‰æ˜çœŸçš„éƒ¨åˆ†
- è¤‡é›œçš„è¬¬èª¤å¯èƒ½æœ‰å…§éƒ¨ä¸€è‡´çš„ç³»çµ±ï¼Œä½†è·¨é ˜åŸŸæ•´åˆæ™‚æœƒæš´éœ²å…¶çœŸé¢ç›®`;
  }
  
  gatherContext() {
    return {
      self: this.self.toJSON(),
      situation: this.situation.toJSON(),
      workingMemory: this.workingMemory.toJSON()
    };
  }
  
  selectMostImportant(observations) {
    // æŒ‰å„ªå…ˆç´šæ’åº
    const priorityMap = { high: 3, normal: 2, low: 1 };
    
    observations.sort((a, b) => {
      const pA = priorityMap[a.priority] || 2;
      const pB = priorityMap[b.priority] || 2;
      return pB - pA;
    });
    
    return observations[0];
  }
  
  calculateCycleDelay() {
    // æ ¹æ“šæ´»èºåº¦èª¿æ•´å»¶é²
    const hasHighPriorityEvents = this.eventQueue.some(e => e.priority === 'high');
    
    if (hasHighPriorityEvents) {
      return 100; // å¿«é€ŸéŸ¿æ‡‰
    }
    
    return this.config.cycleDelay;
  }
  
  parseJSON(text) {
    // ç§»é™¤ markdown ä»£ç¢¼å¡Š
    const cleaned = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
    
    try {
      return JSON.parse(cleaned);
    } catch (error) {
      console.error('JSON è§£æéŒ¯èª¤:', error);
      console.error('åŸæ–‡:', text);
      return {};
    }
  }
  
  fallbackORID(observation) {
    return {
      objective: { what: JSON.stringify(observation.data) },
      reflective: { feeling: 'neutral' },
      interpretive: { meaning: 'unknown' },
      decisional: { shouldAct: false, priority: 'low' }
    };
  }
  
  log(message) {
    if (this.config.verbose) {
      console.log(`[Cycle ${this.cycleCount}] ${message}`);
    }
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  stop() {
    this.isRunning = false;
    this.log('ğŸ›‘ Clippy åœæ­¢é‹è¡Œ');
  }
}

module.exports = { ContinuousAgent, SelfSchema, SituationalAwareness, WorkingMemory, DialecticEngine, EpistemicFramework };
